"""
Deep-Sea Nexus Core Module
å°è£…å‘é‡æ£€ç´¢å’Œ RAG å¬å›åŠŸèƒ½
æ”¯æŒåå°è‡ªåŠ¨é¢„çƒ­ + æ™ºèƒ½è§¦å‘
"""

import os
import sys
import gzip
import threading
import time
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from functools import lru_cache

# æ·»åŠ  Deep-Sea Nexus è·¯å¾„ (ä½¿ç”¨ venv-nexus çš„ Python)
SKILL_ROOT = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SKILL_ROOT)  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å½“å‰ç›®å½•
# V2 æºä»£ç åœ¨ PROJECT_ROOT/deepsea-nexus/ ç›®å½•
NEXUS_PATH = SKILL_ROOT  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å½“å‰ç›®å½•

# æ·»åŠ  Deep-Sea Nexus è·¯å¾„
sys.path.insert(0, NEXUS_PATH)
sys.path.insert(0, os.path.join(NEXUS_PATH, 'src', 'retrieval'))
sys.path.insert(0, os.path.join(NEXUS_PATH, 'vector_store'))

# å¯¼å…¥ Deep-Sea Nexus æ ¸å¿ƒæ¨¡å—
try:
    from semantic_recall import SemanticRecall, create_semantic_recall
    from init_chroma import create_vector_store
    from manager import create_manager
    NEXUS_AVAILABLE = True
except ImportError as e:
    NEXUS_AVAILABLE = False
    IMPORT_ERROR = str(e)

# ===================== ç»Ÿä¸€è§¦å‘è¯æ£€æµ‹ï¼ˆå·²ç§»åˆ° utils/triggers.pyï¼‰ =====================
from .utils.triggers import detect_trigger, extract_keywords, smart_parse


# ===================== è‡ªåŠ¨é¢„çƒ­ =====================
# æ¨¡å—åŠ è½½æ—¶è‡ªåŠ¨å¯åŠ¨åå°é¢„çƒ­
_nexus_instance = None

def _get_nexus_instance():
    """è·å–å…¨å±€å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _nexus_instance
    if _nexus_instance is None:
        _nexus_instance = NexusCore()
        # è‡ªåŠ¨åå°é¢„çƒ­
        _nexus_instance.start_background_warmup()
    return _nexus_instance


@dataclass
class RecallResult:
    """æ£€ç´¢ç»“æœ"""
    content: str
    source: str
    relevance: float
    metadata: Dict[str, Any] = None


class NexusCore:
    """Deep-Sea Nexus æ ¸å¿ƒç±»"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.recall = None
            self.manager = None
            self.store = None
            self._warming = False
            self._ready = False
            self._warmup_thread = None
            NexusCore._initialized = True
    
    def _background_warmup(self):
        """åå°é¢„çƒ­çº¿ç¨‹"""
        self._warming = True
        try:
            if not NEXUS_AVAILABLE:
                return
            
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨
            self.store = create_vector_store()
            
            # åˆ›å»ºç®¡ç†å™¨
            self.manager = create_manager(
                self.store.embedder,
                self.store.collection
            )
            
            # åˆ›å»ºè¯­ä¹‰æ£€ç´¢
            self.recall = create_semantic_recall(self.manager)
            
            self._ready = True
            print(f"âœ“ Deep-Sea Nexus é¢„çƒ­å®Œæˆ ({self.get_stats().get('total_documents', '?')} æ–‡æ¡£)")
        except Exception as e:
            print(f"âœ— é¢„çƒ­å¤±è´¥: {e}")
            self._warming = False
    
    def start_background_warmup(self):
        """å¯åŠ¨åå°é¢„çƒ­ï¼ˆéé˜»å¡ï¼‰"""
        if self._ready or self._warming:
            return  # å·²ç»åœ¨è¿è¡Œæˆ–å·²å°±ç»ª
        
        self._warmup_thread = threading.Thread(target=self._background_warmup, daemon=True)
        self._warmup_thread.start()
        print("ğŸ”„ Deep-Sea Nexus åå°é¢„çƒ­ä¸­...")
    
    def wait_for_ready(self, timeout: float = 120.0):
        """ç­‰å¾…é¢„çƒ­å®Œæˆ"""
        start = time.time()
        while not self._ready and not self.recall:
            if self._warmup_thread and not self._warmup_thread.is_alive() and not self._ready:
                break  # çº¿ç¨‹å·²ç»“æŸä½†å¤±è´¥äº†
            if time.time() - start > timeout:
                raise TimeoutError("é¢„çƒ­è¶…æ—¶")
            time.sleep(0.5)
    
    def init(self) -> bool:
        """åŒæ­¥åˆå§‹åŒ–ï¼ˆé˜»å¡ï¼‰"""
        if not NEXUS_AVAILABLE:
            return False
        
        try:
            print("ğŸ”„ åˆå§‹åŒ– Deep-Sea Nexus...")
            
            # åˆå§‹åŒ–å‘é‡å­˜å‚¨
            self.store = create_vector_store()
            
            # åˆ›å»ºç®¡ç†å™¨
            self.manager = create_manager(
                self.store.embedder,
                self.store.collection
            )
            
            # åˆ›å»ºè¯­ä¹‰æ£€ç´¢
            self.recall = create_semantic_recall(self.manager)
            
            self._ready = True
            print(f"âœ“ Deep-Sea Nexus å·²å°±ç»ª")
            print(f"  ğŸ“Š å·²ç´¢å¼•: {self.get_stats().get('total_documents', 'N/A')} æ¡")
            
            return True
        except Exception as e:
            print(f"âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    # ===================== ç¼“å­˜å±‚ =====================
    
    @lru_cache(maxsize=128)
    def _cached_search(self, query: str, n: int) -> tuple:
        """ç¼“å­˜æœç´¢ç»“æœ"""
        if self.recall is None:
            return ()
        
        try:
            results = self.recall.search(query, n_results=n)
            return tuple((r.content, r.metadata.get('title', r.doc_id), r.relevance_score) for r in results)
        except Exception:
            return ()
    
    def search_recall(self, query: str, n: int = 5, timeout: float = 120.0) -> List[RecallResult]:
        """è¯­ä¹‰æ£€ç´¢ï¼ˆæ”¯æŒè‡ªåŠ¨é¢„çƒ­ï¼‰"""
        # å¯åŠ¨åå°é¢„çƒ­ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
        if not self._ready and not self._warming:
            self.start_background_warmup()
        
        # å¦‚æœè¿˜æ²¡å‡†å¤‡å¥½ï¼Œç­‰å¾…
        if not self._ready:
            try:
                self.wait_for_ready(timeout)
            except TimeoutError:
                return []
        
        if self.recall is None:
            return []
        
        try:
            # ä½¿ç”¨ç¼“å­˜
            cached = self._cached_search(query, n)
            if cached:
                return [
                    RecallResult(
                        content=content,
                        source=source,
                        relevance=relevance,
                        metadata={}
                    )
                    for content, source, relevance in cached
                ]
            
            results = self.recall.search(query, n_results=n)
            
            return [
                RecallResult(
                    content=r.content,
                    source=r.metadata.get('title', r.doc_id),
                    relevance=r.relevance_score,
                    metadata=r.metadata
                )
                for r in results
            ]
        except Exception as e:
            print(f"æ£€ç´¢é”™è¯¯: {e}")
            return []
    
    def search(self, query: str, n: int = 5) -> List[RecallResult]:
        """è¯­ä¹‰æœç´¢"""
        return self.search_recall(query, n)
    
    # ===================== å¢é‡ç´¢å¼• =====================
    
    def add_document(self, content: str, title: str = "", tags: str = "", 
                     note_id: str = None) -> Optional[str]:
        """
        æ·»åŠ å•ä¸ªæ–‡æ¡£åˆ°ç´¢å¼•ï¼ˆå¢é‡ç´¢å¼•ï¼‰
        
        Args:
            content: æ–‡æ¡£å†…å®¹
            title: æ–‡æ¡£æ ‡é¢˜
            tags: æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰
            note_id: è‡ªå®šä¹‰æ–‡æ¡£IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ–‡æ¡£ID æˆ– None
        """
        if self.manager is None:
            if not self.init():
                return None
        
        try:
            metadata = {"title": title or "Untitled"}
            if tags:
                metadata["tags"] = [t.strip() for t in tags.split(",")]
            
            doc_id = self.manager.add_note(
                content=content,
                metadata=metadata,
                note_id=note_id  # ä¿®å¤å‚æ•°å
            )
            
            # æ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿æ–°æ–‡æ¡£å¯æ£€ç´¢
            self._cached_search.cache_clear()
            
            return doc_id
        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return None
    
    def add_documents(self, documents: List[Dict[str, str]], 
                      batch_size: int = 10) -> List[str]:
        """
        æ‰¹é‡æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ [{content, title, tags, doc_id?}]
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            List[str]: æˆåŠŸæ·»åŠ çš„æ–‡æ¡£IDåˆ—è¡¨
        """
        results = []
        
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            
            for doc in batch:
                doc_id = self.add_document(
                    content=doc.get("content", ""),
                    title=doc.get("title", ""),
                    tags=doc.get("tags", ""),
                    doc_id=doc.get("doc_id")
                )
                
                if doc_id:
                    results.append(doc_id)
        
        # æ¸…é™¤ç¼“å­˜
        self._cached_search.cache_clear()
        
        return results
    
    def add(self, content: str, title: str, tags: str = "") -> Optional[str]:
        """æ·»åŠ ç¬”è®°ï¼ˆåˆ«åï¼‰"""
        return self.add_document(content, title, tags)
    
    # ===================== å‹ç¼©å½’æ¡£ =====================
    
    def compress_session(self, session_path: str, compressed_path: str = None) -> str:
        """
        å‹ç¼©ä¼šè¯æ–‡ä»¶
        
        Args:
            session_path: åŸå§‹ä¼šè¯æ–‡ä»¶è·¯å¾„
            compressed_path: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: å‹ç¼©æ–‡ä»¶è·¯å¾„
        """
        if compressed_path is None:
            compressed_path = session_path + ".gz"
        
        try:
            with open(session_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    f_out.write(f_in.read())
            
            return compressed_path
        except Exception as e:
            print(f"å‹ç¼©å¤±è´¥: {e}")
            return ""
    
    def decompress_session(self, compressed_path: str, output_path: str = None) -> str:
        """
        è§£å‹ä¼šè¯æ–‡ä»¶
        
        Args:
            compressed_path: å‹ç¼©æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è¦†ç›–åŸæ–‡ä»¶ï¼‰
            
        Returns:
            str: è§£å‹åçš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = compressed_path.replace('.gz', '')
        
        try:
            with gzip.open(compressed_path, 'rb') as f_in:
                with open(output_path, 'wb') as f_out:
                    f_out.write(f_in.read())
            
            return output_path
        except Exception as e:
            print(f"è§£å‹å¤±è´¥: {e}")
            return ""
    
    def stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡"""
        if self.manager is None:
            return {"total_documents": 0, "status": "æœªåˆå§‹åŒ–"}
        
        try:
            stats = self.recall.get_recall_stats()
            return {
                "total_documents": stats.get("total_documents", 0),
                "collection_name": stats.get("collection_name", "N/A"),
                "status": "æ­£å¸¸"
            }
        except Exception:
            return {"total_documents": 0, "status": "é”™è¯¯"}
    
    def health(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            "available": NEXUS_AVAILABLE,
            "initialized": self.recall is not None,
            "documents": self.stats().get("total_documents", 0),
            "version": "2.0.0"
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ï¼ˆåˆ«åï¼‰"""
        return self.stats()


# ===================== å…¨å±€å®ä¾‹ =====================
_nexus = None


def _get_nexus() -> NexusCore:
    """è·å–å…¨å±€å®ä¾‹"""
    global _nexus
    if _nexus is None:
        _nexus = NexusCore()
        # è‡ªåŠ¨åå°é¢„çƒ­
        _nexus.start_background_warmup()
    return _nexus


# ===================== æ™ºèƒ½æœç´¢ =====================
# AI å¯ä»¥åœ¨æ¯æ¬¡å¯¹è¯å‰è°ƒç”¨è¿™äº›å‡½æ•°

def smart_search(user_input: str, n: int = 3) -> Dict[str, Any]:
    """
    æ™ºèƒ½æœç´¢ - æ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨æœç´¢è®°å¿†
    
    1. å…ˆæ£€æµ‹è§¦å‘è¯ ("è¿˜è®°å¾—"ã€"ä¸Šæ¬¡æåˆ°" ç­‰)
    2. è§¦å‘æ—¶æ‰§è¡Œç²¾ç¡®æœç´¢
    3. éè§¦å‘æ—¶æå–å…³é”®è¯æ‰§è¡Œè¯­ä¹‰æœç´¢
    
    Args:
        user_input: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
        n: è¿”å›ç»“æœæ•°é‡
    
    Returns:
        Dict: {
            "triggered": bool,  # æ˜¯å¦è§¦å‘
            "query": str,       # æœç´¢è¯
            "results": str,     # æ ¼å¼åŒ–ç»“æœ
            "context": str      # å¯ç›´æ¥æ³¨å…¥çš„ä¸Šä¸‹æ–‡
        }
    """
    nexus = _get_nexus()
    
    # å¦‚æœè¿˜æ²¡å‡†å¤‡å¥½ï¼Œè¿”å›ç©º
    if not nexus._ready and not nexus.recall:
        return {"triggered": False, "query": "", "results": "", "context": ""}
    
    # 1. æ£€æµ‹è§¦å‘è¯
    trigger = detect_trigger(user_input)
    
    if trigger:
        # è§¦å‘æ¨¡å¼ï¼šä½¿ç”¨åŸå§‹æŸ¥è¯¢è¯ç²¾ç¡®æœç´¢
        query = trigger["query"]
        results = nexus.search_recall(query, n)
        
        return {
            "triggered": True,
            "query": query,
            "trigger_pattern": trigger["pattern"],
            "results": _format_results(results, query),
            "context": _build_context(results)
        }
    
    # 2. éè§¦å‘æ¨¡å¼ï¼šæå–å…³é”®è¯æœç´¢
    keywords = extract_keywords(user_input, 3)
    
    if not keywords:
        return {"triggered": False, "query": "", "results": "", "context": ""}
    
    # åˆå¹¶å…³é”®è¯æœç´¢
    all_results = []
    seen = set()
    
    for kw in keywords:
        results = nexus.search_recall(kw, n)
        for r in results:
            if r.content[:100] not in seen:
                seen.add(r.content[:100])
                all_results.append(r)
    
    # æŒ‰ç›¸å…³æ€§æ’åº
    all_results.sort(key=lambda x: x.relevance, reverse=True)
    all_results = all_results[:n]
    
    return {
        "triggered": False,
        "query": " ".join(keywords),
        "keywords": keywords,
        "results": _format_results(all_results, user_input),
        "context": _build_context(all_results)
    }


def auto_search(user_input: str, n: int = 3) -> str:
    """
    è‡ªåŠ¨æœç´¢ - è¿”å›æ ¼å¼åŒ–çš„è®°å¿†ä¸Šä¸‹æ–‡
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        n: ç»“æœæ•°é‡
    
    Returns:
        str: æ ¼å¼åŒ–çš„è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆæ— ç»“æœè¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    result = smart_search(user_input, n)
    return result["context"]


def _format_results(results: List[RecallResult], query: str) -> str:
    """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
    if not results:
        return f"ğŸ” æœªæ‰¾åˆ°ä¸ \"{query}\" ç›¸å…³çš„è®°å¿†"
    
    lines = [f"ğŸ” æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†:\n"]
    
    for i, r in enumerate(results, 1):
        lines.append(f"{i}. [{r.relevance:.1%}] **{r.source}**")
        content = r.content[:150] + "..." if len(r.content) > 150 else r.content
        lines.append(f"   {content}")
        lines.append("")
    
    return "\n".join(lines)


def _build_context(results: List[RecallResult]) -> str:
    """æ„å»ºå¯æ³¨å…¥ä¸Šä¸‹æ–‡çš„å­—ç¬¦ä¸²"""
    if not results:
        return ""
    
    lines = ["**ç›¸å…³è®°å¿†ï¼š**\n"]
    for i, r in enumerate(results, 1):
        lines.append(f"{i}. **{r.source}**")
        content = r.content[:200] + "..." if len(r.content) > 200 else r.content
        lines.append(f"   {content}")
        lines.append("")
    
    return "\n".join(lines)


def nexus_init(blocking: bool = False) -> bool:
    """åˆå§‹åŒ–
    Args:
        blocking: æ˜¯å¦é˜»å¡ç­‰å¾…é¢„çƒ­å®Œæˆ
    """
    nexus = _get_nexus()
    if blocking:
        return nexus.init()
    else:
        nexus.start_background_warmup()
        return True


def nexus_recall(query: str, n: int = 5) -> List[RecallResult]:
    """è¯­ä¹‰æ£€ç´¢"""
    return _get_nexus().search_recall(query, n)


def nexus_search(query: str, n: int = 5) -> List[RecallResult]:
    """è¯­ä¹‰æœç´¢"""
    return _get_nexus().search(query, n)


def nexus_add(content: str, title: str, tags: str = "") -> Optional[str]:
    """æ·»åŠ ç¬”è®°"""
    return _get_nexus().add(content, title, tags)


def nexus_add_structured_summary(
    core_output: str,
    tech_points: List[str] = None,
    code_pattern: str = "",
    decision_context: str = "",
    pitfall_record: str = "",
    applicable_scene: str = "",
    search_keywords: List[str] = None,
    projectå…³è”: str = "",
    confidence: str = "medium",
    source: str = ""
) -> Dict[str, Any]:
    """
    æ·»åŠ ç»“æ„åŒ–æ‘˜è¦ï¼ˆè®©ç¬¬äºŒå¤§è„‘è¶Šæ¥è¶Šèªæ˜ï¼‰
    
    Args:
        core_output: æœ¬æ¬¡æ ¸å¿ƒäº§å‡º
        tech_points: æŠ€æœ¯è¦ç‚¹åˆ—è¡¨
        code_pattern: ä»£ç æ¨¡å¼
        decision_context: å†³ç­–ä¸Šä¸‹æ–‡
        pitfall_record: é¿å‘è®°å½•
        applicable_scene: é€‚ç”¨åœºæ™¯
        search_keywords: æœç´¢å…³é”®è¯
        projectå…³è”: é¡¹ç›®å…³è”
        confidence: ç½®ä¿¡åº¦
        source: æ¥æºæ ‡è¯†
        
    Returns:
        Dict with stored doc IDs and summary data
    """
    nexus = _get_nexus()
    
    # æ„å»ºå¯æœç´¢çš„æ–‡æœ¬
    parts = [
        core_output,
        " ".join(tech_points or []),
        code_pattern,
        decision_context,
        pitfall_record,
        applicable_scene,
        " ".join(search_keywords or []),
        projectå…³è”,
    ]
    searchable_text = " ".join(p for p in parts if p)
    
    # æ„å»ºæ ‡ç­¾
    tags_list = ["type:structured_summary", f"confidence:{confidence}"]
    if search_keywords:
        tags_list.extend(search_keywords)
    if source:
        tags_list.append(f"source:{source}")
    tags = ",".join(tags_list)
    
    results = {
        "stored_count": 0,
        "doc_ids": [],
        "summary_data": {
            "core_output": core_output,
            "tech_points": tech_points,
            "code_pattern": code_pattern,
            "decision_context": decision_context,
            "pitfall_record": pitfall_record,
            "applicable_scene": applicable_scene,
            "search_keywords": search_keywords,
            "projectå…³è”": projectå…³è”,
            "confidence": confidence,
        }
    }
    
    try:
        # 1. å­˜å‚¨ä¸»æ‘˜è¦ï¼ˆå¯æœç´¢ï¼‰
        doc_id1 = nexus.add(
            content=searchable_text,
            title=f"ç»“æ„åŒ–æ‘˜è¦ - {core_output[:50]}...",
            tags=tags
        )
        if doc_id1:
            results["stored_count"] += 1
            results["doc_ids"].append(doc_id1)
        
        # 2. å­˜å‚¨å…ƒæ•°æ®ï¼ˆJSON æ ¼å¼ï¼Œä¿ç•™ç»“æ„ï¼‰
        import json
        metadata_json = json.dumps(results["summary_data"], ensure_ascii=False)
        doc_id2 = nexus.add(
            content=metadata_json,
            title=f"æ‘˜è¦å…ƒæ•°æ® - {core_output[:50]}...",
            tags=f"type:summary_metadata,source:{source}"
        )
        if doc_id2:
            results["stored_count"] += 1
            results["doc_ids"].append(doc_id2)
        
        # 3. å…³é”®è¯å•ç‹¬ç´¢å¼•ï¼ˆæå‡æ£€ç´¢ç²¾åº¦ï¼‰
        if search_keywords:
            keyword_text = " ".join(search_keywords)
            doc_id3 = nexus.add(
                content=keyword_text,
                title=f"å…³é”®è¯ç´¢å¼• - {core_output[:30]}...",
                tags=f"type:keywords,source:{source}"
            )
            if doc_id3:
                results["stored_count"] += 1
                results["doc_ids"].append(doc_id3)
        
    except Exception as e:
        print(f"å­˜å‚¨ç»“æ„åŒ–æ‘˜è¦å¤±è´¥: {e}")
        results["error"] = str(e)
    
    return results


def nexus_add_document(content: str, title: str = "", tags: str = "", 
                       note_id: str = None) -> Optional[str]:
    """æ·»åŠ æ–‡æ¡£ï¼ˆå¢é‡ç´¢å¼•ï¼‰"""
    return _get_nexus().add_document(content, title, tags, note_id)


def nexus_add_documents(documents: List[Dict[str, str]], 
                        batch_size: int = 10) -> List[str]:
    """æ‰¹é‡æ·»åŠ æ–‡æ¡£"""
    return _get_nexus().add_documents(documents, batch_size)


def nexus_compress_session(session_path: str, compressed_path: str = None) -> str:
    """å‹ç¼©ä¼šè¯æ–‡ä»¶"""
    return _get_nexus().compress_session(session_path, compressed_path)


def nexus_decompress_session(compressed_path: str, output_path: str = None) -> str:
    """è§£å‹ä¼šè¯æ–‡ä»¶"""
    return _get_nexus().decompress_session(compressed_path, output_path)


def nexus_stats() -> Dict[str, Any]:
    """è·å–ç»Ÿè®¡"""
    return _get_nexus().stats()


def nexus_health() -> Dict[str, Any]:
    """å¥åº·æ£€æŸ¥"""
    return _get_nexus().health()


# CLI å…¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Deep-Sea Nexus CLI")
    parser.add_argument("command", choices=["init", "recall", "add", "stats", "health", "compress"])
    parser.add_argument("query", nargs="?", help="æŸ¥è¯¢è¯")
    parser.add_argument("--n", type=int, default=5, help="ç»“æœæ•°é‡")
    parser.add_argument("--title", help="ç¬”è®°æ ‡é¢˜")
    parser.add_argument("--tags", help="æ ‡ç­¾")
    parser.add_argument("--input", help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    if args.command == "init":
        nexus_init()
    elif args.command == "recall":
        results = nexus_recall(args.query or "", args.n)
        for r in results:
            print(f"[{r.relevance:.2f}] {r.source}")
    elif args.command == "add":
        if args.title:
            import sys
            content = sys.stdin.read() if not args.query else args.query
            nexus_add(content, args.title, args.tags or "")
    elif args.command == "stats":
        print(nexus_stats())
    elif args.command == "health":
        print(nexus_health())
    elif args.command == "compress":
        if args.input:
            result = nexus_compress_session(args.input, args.output)
            print(f"âœ“ å‹ç¼©å®Œæˆ: {result}")
