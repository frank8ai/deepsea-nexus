#!/usr/bin/env python3
"""
ä¼šè¯è®°å½•å¯¼å…¥è„šæœ¬ - å°†å†å²ä¼šè¯å¯¼å…¥å‘é‡åº“
"""

import os
import sys
import glob
import yaml
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ  Deep-Sea Nexus è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
NEXUS_PATH = os.path.join(PROJECT_ROOT, 'DEEP_SEA_NEXUS_V2')
sys.path.insert(0, NEXUS_PATH)
sys.path.insert(0, os.path.join(NEXUS_PATH, 'src', 'vector_store'))
sys.path.insert(0, os.path.join(NEXUS_PATH, 'src', 'retrieval'))

try:
    from init_chroma import create_vector_store
    from manager import create_manager
    from semantic_recall import create_semantic_recall
    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  è­¦å‘Š: {e}")
    DEPENDENCIES_AVAILABLE = False


def load_config() -> dict:
    """åŠ è½½é…ç½®"""
    config_path = os.path.join(NEXUS_PATH, 'config.yaml')
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def parse_session_file(file_path: str) -> Dict[str, Any]:
    """è§£æä¼šè¯æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– frontmatter
    lines = content.split('\n')
    metadata = {}
    body = []
    in_frontmatter = False
    in_body = False
    
    for line in lines:
        if line.strip() == '---':
            if not in_frontmatter:
                in_frontmatter = True
            else:
                in_body = True
            continue
        
        if in_frontmatter and ':' in line:
            key = line.split(':')[0].strip()
            value = line.split(':', 1)[1].strip()
            if value.startswith('[') or value.startswith('{'):
                try:
                    value = eval(value)
                except:
                    pass
            metadata[key] = value
        elif in_body:
            body.append(line)
    
    return {
        'title': metadata.get('title', Path(file_path).stem),
        'content': '\n'.join(body),
        'uuid': metadata.get('uuid', ''),
        'created': metadata.get('created', ''),
        'tags': metadata.get('tags', []),
        'type': metadata.get('type', 'session'),
        'source': file_path
    }


def import_sessions(session_dir: str, store, config: dict) -> Dict[str, Any]:
    """å¯¼å…¥ä¼šè¯ç›®å½•ä¸‹çš„æ‰€æœ‰ä¼šè¯"""
    session_files = glob.glob(os.path.join(session_dir, 'session_*.md'))
    
    stats = {
        'total': len(session_files),
        'imported': 0,
        'failed': 0,
        'chunks': 0
    }
    
    # ä»æ–‡ä»¶åæå–æ—¥æœŸ
    date_match = os.path.basename(session_dir)
    
    for file_path in session_files:
        try:
            session_data = parse_session_file(file_path)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                'title': session_data['title'],
                'source_file': session_data['source'],
                'type': 'session',
                'date': date_match,
                'uuid': session_data['uuid'],
                'created_at': session_data['created'],
                'tags': ','.join(session_data['tags']) if session_data['tags'] else 'session'
            }
            
            # æ·»åŠ åˆ°å‘é‡åº“
            doc_id = store.add_note(
                content=session_data['content'],
                metadata=metadata
            )
            
            stats['imported'] += 1
            print(f"âœ… å¯¼å…¥: {session_data['title']}")
            
        except Exception as e:
            stats['failed'] += 1
            print(f"âŒ å¤±è´¥: {os.path.basename(file_path)} - {e}")
    
    return stats


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ä¼šè¯è®°å½•å¯¼å…¥å·¥å…·")
    print("=" * 60)
    
    if not DEPENDENCIES_AVAILABLE:
        print("âŒ ç¼ºå°‘ä¾èµ–ï¼Œè¯·å…ˆå®‰è£… chromadb å’Œ sentence-transformers")
        return
    
    # åŠ è½½é…ç½®
    config = load_config()
    print(f"âœ… é…ç½®åŠ è½½å®Œæˆ")
    
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
    store = create_vector_store(config_path=os.path.join(NEXUS_PATH, 'config.yaml'))
    print(f"âœ… å‘é‡åº“è¿æ¥æˆåŠŸ: {store.collection.name}")
    
    # æŸ¥æ‰¾ä¼šè¯ç›®å½•
    session_dirs = [
        # Deep-Sea Nexus å¤‡ä»½ä¸­çš„ä¼šè¯
        os.path.join(PROJECT_ROOT, 'DEEP_SEA_NEXUS_V2/memory/90_Memory/2026-02'),
        os.path.join(PROJECT_ROOT, '~/Library/CloudStorage/GoogleDrive*/frank20170808@gmail.com/å…¶ä»–è®¡ç®—æœº/æˆ‘çš„è®¡ç®—æœº (2)/Documents/frank/ç¼–ç¨‹å­¦ä¹ /0.01-é˜¿çˆªç‹¬ç«‹å·¥ä½œåŒº/DEEP_SEA_NEXUS_V2/memory/90_Memory/2026-02'),
        # å·¥ä½œåŒºä¸­çš„ä¼šè¯
        os.path.join(PROJECT_ROOT, 'memory/90_Memory/2026-02'),
    ]
    
    all_stats = {
        'total': 0,
        'imported': 0,
        'failed': 0,
        'chunks': 0
    }
    
    for session_dir in session_dirs:
        # å±•å¼€ ~
        session_dir = os.path.expanduser(session_dir)
        
        if os.path.exists(session_dir):
            print(f"\nğŸ“ å‘ç°ä¼šè¯ç›®å½•: {session_dir}")
            stats = import_sessions(session_dir, store, config)
            
            all_stats['total'] += stats['total']
            all_stats['imported'] += stats['imported']
            all_stats['failed'] += stats['failed']
        else:
            print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {session_dir}")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print("\n" + "=" * 60)
    print("å¯¼å…¥å®Œæˆ!")
    print(f"ğŸ“Š æ€»è®¡:")
    print(f"  - å‘ç°ä¼šè¯: {all_stats['total']}")
    print(f"  - æˆåŠŸå¯¼å…¥: {all_stats['imported']}")
    print(f"  - å¤±è´¥: {all_stats['failed']}")
    print(f"  - å‘é‡åº“æ–‡æ¡£æ•°: {store.collection.count()}")
    print("=" * 60)


if __name__ == "__main__":
    main()
