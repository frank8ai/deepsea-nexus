#!/usr/bin/env python3
"""
Generate safe Smart Context digests (report-only) for morning/progress/nightly runs.

No external side effects:
- reads memory/session/research files
- writes a markdown report under logs/digests/YYYY-MM-DD/
"""

from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Tuple


SUMMARY_FIELDS = [
    "æœ¬æ¬¡æ ¸å¿ƒäº§å‡º",
    "æŠ€æœ¯è¦ç‚¹",
    "ä»£ç æ¨¡å¼",
    "å†³ç­–ä¸Šä¸‹æ–‡",
    "é¿å‘è®°å½•",
    "é€‚ç”¨åœºæ™¯",
    "æœç´¢å…³é”®è¯",
    "é¡¹ç›®å…³è”",
    "ç½®ä¿¡åº¦",
]


@dataclass
class DigestStats:
    session_files: int
    paused_sessions: int
    gold_hits: int
    pack_files: int
    card_files: int
    sessions_missing_summary: int
    sessions_missing_json: int


def load_config(repo_root: Path) -> dict:
    config_path = repo_root / "config.json"
    if not config_path.exists():
        return {}
    try:
        return json.loads(config_path.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        return {}


def resolve_workspace(repo_root: Path, override: str | None) -> Path:
    if override:
        return Path(override).expanduser().resolve()
    cfg = load_config(repo_root)
    base = cfg.get("paths", {}).get("base")
    if base:
        return Path(base).expanduser().resolve()
    return repo_root.parent


def _extract_gold_and_paused(text: str) -> Tuple[int, int]:
    gold_hits = len(re.findall(r"#GOLD", text, flags=re.IGNORECASE))
    paused_hits = len(re.findall(r"#PAUSED", text, flags=re.IGNORECASE))
    return gold_hits, paused_hits


def _json_blocks(content: str) -> List[str]:
    return re.findall(r"```json\s*\n([\s\S]*?)\n```", content, flags=re.MULTILINE)


def _has_structured_summary_json(content: str) -> bool:
    for block in _json_blocks(content):
        try:
            data = json.loads(block)
        except json.JSONDecodeError:
            continue
        if all(k in data for k in SUMMARY_FIELDS):
            return True
    return False


def collect_stats(workspace: Path, day: datetime) -> Tuple[DigestStats, List[str], List[str]]:
    day_dir = workspace / "90_Memory" / day.strftime("%Y-%m-%d")
    daily_index = day_dir / "_DAILY_INDEX.md"

    session_files = sorted(day_dir.glob("session_*.md")) if day_dir.exists() else []
    pack_files = sorted(day_dir.glob("*deep-research-pack.md"))
    card_files = sorted(day_dir.glob("*deep-research-card.md"))

    daily_text = daily_index.read_text(encoding="utf-8") if daily_index.exists() else ""
    gold_hits_daily, paused_hits_daily = _extract_gold_and_paused(daily_text)

    missing_summary: List[str] = []
    missing_json: List[str] = []

    for session in session_files:
        txt = session.read_text(encoding="utf-8")
        if "## ðŸ“‹ æ€»ç»“" not in txt:
            missing_summary.append(session.name)
        if not _has_structured_summary_json(txt):
            missing_json.append(session.name)

    stats = DigestStats(
        session_files=len(session_files),
        paused_sessions=paused_hits_daily,
        gold_hits=gold_hits_daily,
        pack_files=len(pack_files),
        card_files=len(card_files),
        sessions_missing_summary=len(missing_summary),
        sessions_missing_json=len(missing_json),
    )
    return stats, missing_summary, missing_json


def render_digest(mode: str, workspace: Path, day: datetime, stats: DigestStats, missing_summary: List[str], missing_json: List[str]) -> str:
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    day_str = day.strftime("%Y-%m-%d")

    focus_line = {
        "morning": "ä»Šå¤©ä¼˜å…ˆæŽ¨è¿›ï¼šæ´»è·ƒä¼šè¯ä¸Žç ”ç©¶å·¥ä»¶å®Œæ•´æ€§ã€‚",
        "progress": "è¿›åº¦æ£€æŸ¥ï¼šç¡®è®¤æ–°å¢žå†³ç­–æ˜¯å¦å·²å†™å…¥ #GOLD ä¸Ž session sliceã€‚",
        "nightly": "å¤œé—´æ²‰æ·€ï¼šå½’æ¡£ä»Šæ—¥äº§å‡ºå¹¶æ ‡æ³¨å¯å¤ç”¨èµ„äº§ã€‚",
    }.get(mode, "Smart Context digest")

    suggestions = []
    if stats.sessions_missing_summary > 0:
        suggestions.append(f"è¡¥é½ {stats.sessions_missing_summary} ä¸ª session çš„ `## ðŸ“‹ æ€»ç»“`ã€‚")
    if stats.sessions_missing_json > 0:
        suggestions.append(f"è¡¥é½ {stats.sessions_missing_json} ä¸ª session çš„ç»“æž„åŒ– JSON v3.1ã€‚")
    if stats.pack_files == 0 and stats.card_files == 0:
        suggestions.append("ä»Šæ—¥å°šæ—  Pack/Cardï¼Œè‡³å°‘äº§å‡º 1 ç»„ç ”ç©¶å·¥ä»¶ã€‚")
    if not suggestions:
        suggestions = ["å½“å‰æ²‰æ·€å®Œæ•´ï¼Œç»§ç»­æŒ‰åŒè½¨è¯æ®æŽ¨è¿›ä¸‹ä¸€ä»»åŠ¡ã€‚"]

    missing_summary_block = "\n".join(f"- {name}" for name in missing_summary[:20]) or "- æ— "
    missing_json_block = "\n".join(f"- {name}" for name in missing_json[:20]) or "- æ— "
    suggestions_block = "\n".join(f"- {item}" for item in suggestions)

    return f"""# Smart Context Digest ({mode})

- Generated at: {now}
- Workspace: `{workspace}`
- Date scope: `{day_str}`

## Focus
{focus_line}

## Snapshot
- Session slices: {stats.session_files}
- #PAUSED marks (daily index): {stats.paused_sessions}
- #GOLD marks (daily index): {stats.gold_hits}
- Deep Research Pack: {stats.pack_files}
- Deep Research Card: {stats.card_files}

## Quality Gates
- Sessions missing `## ðŸ“‹ æ€»ç»“`: {stats.sessions_missing_summary}
- Sessions missing structured JSON v3.1: {stats.sessions_missing_json}

## Missing Summary Files
{missing_summary_block}

## Missing JSON Files
{missing_json_block}

## Recommended Next Actions
{suggestions_block}
"""


def write_report(workspace: Path, mode: str, content: str, day: datetime) -> Path:
    out_dir = workspace / "logs" / "digests" / day.strftime("%Y-%m-%d")
    out_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%H%M%S")
    out_path = out_dir / f"{mode}-{ts}.md"
    out_path.write_text(content, encoding="utf-8")
    return out_path


def main() -> int:
    parser = argparse.ArgumentParser(description="Generate safe Smart Context digest")
    parser.add_argument("--repo-root", default=str(Path(__file__).resolve().parents[1]), help="Deep-Sea Nexus repo root")
    parser.add_argument("--workspace", default=None, help="Override workspace path")
    parser.add_argument("--mode", choices=["morning", "progress", "nightly"], default="nightly")
    parser.add_argument("--date", default=None, help="Date in YYYY-MM-DD, default today")
    parser.add_argument("--dry-run", action="store_true", help="Print report, do not write file")
    args = parser.parse_args()

    repo_root = Path(args.repo_root).expanduser().resolve()
    workspace = resolve_workspace(repo_root, args.workspace)

    if args.date:
        day = datetime.strptime(args.date, "%Y-%m-%d")
    else:
        day = datetime.now()

    stats, missing_summary, missing_json = collect_stats(workspace, day)
    report = render_digest(args.mode, workspace, day, stats, missing_summary, missing_json)

    if args.dry_run:
        print(report)
        return 0

    out_path = write_report(workspace, args.mode, report, day)
    print(f"[digest] mode={args.mode} output={out_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
