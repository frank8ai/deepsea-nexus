"""
Smart Context - ç¬¬äºŒå¤§è„‘æ ¸å¿ƒå­åŠŸèƒ½

åŠŸèƒ½ï¼š
1. å¯¹è¯æ‘˜è¦å­˜å‚¨ - æ ¹æ®è§„åˆ™ä¿ç•™åŸæ–‡+æ‘˜è¦ï¼ˆå·²å‹ç¼©ï¼‰
2. è®°å¿†åº“æ³¨å…¥ - æå–è®°å¿†åº“å…³é”®ä¿¡æ¯æ³¨å…¥ä¸Šä¸‹æ–‡
3. ä¸Šä¸‹æ–‡å‹ç¼©è§„åˆ™ - æ ¹æ®å¯¹è¯è½®æ•°å‹ç¼©
4. å‹ç¼©å‰æŠ¢æ•‘ - NOW.md æŠ¢æ•‘æœºåˆ¶

è®¾è®¡ç†å¿µï¼š
- å’Œç¬¬äºŒå¤§è„‘ä¸€èµ·å¯åŠ¨
- æ¯æ¬¡å¯¹è¯å â†’ å­˜å‚¨æ‘˜è¦
- æ¯æ¬¡å¯¹è¯å‰ â†’ æ³¨å…¥ä¸Šä¸‹æ–‡
- å‹ç¼©å‰ â†’ æŠ¢æ•‘å…³é”®ä¿¡æ¯

é›†æˆä½ç½®ï¼š
- plugins/smart_context.py
- å’Œ nexus_coreã€session_manager ä¸€èµ·å¯åŠ¨
"""

import re
import json
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

from ..nexus_core import NexusCore
from .session_manager import SessionManagerPlugin
from ..core.plugin_system import NexusPlugin, PluginMetadata
from ..core.event_bus import EventTypes
from ..compat_async import run_coro_sync
from ..brain.graph_api import configure_graph, graph_add_edge, graph_related_with_evidence


# ===================== é…ç½® =====================

@dataclass
class ContextCompressionConfig:
    """
    ä¸Šä¸‹æ–‡å‹ç¼©é…ç½®
    
    è§„åˆ™é…ç½®ï¼š
    - ä»€ä¹ˆæ—¶å€™å­˜å‚¨æ‘˜è¦
    - ä»€ä¹ˆæ—¶å€™æ³¨å…¥ä¸Šä¸‹æ–‡
    - æ ¹æ®å¯¹è¯è½®æ•°å‹ç¼©
    - å‹ç¼©å‰æŠ¢æ•‘å…³é”®ä¿¡æ¯
    """
    # å¯¹è¯è½®æ•°è§„åˆ™ - ç¼–ç¨‹ä»»åŠ¡ä¼˜åŒ–é…ç½®
    full_rounds: int = 8          # å®Œæ•´ä¿ç•™æœ€è¿‘ 8 è½® (ç¼–ç¨‹éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡)
    summary_rounds: int = 20      # è¶…è¿‡ 20 è½®åªä¿ç•™æ‘˜è¦ (ä¿ç•™å…³é”®å†³ç­–)
    compress_after_rounds: int = 35  # è¶…è¿‡ 35 è½®å‹ç¼© (é•¿ä»»åŠ¡å½’æ¡£)
    
    # æ‘˜è¦å­˜å‚¨è§„åˆ™
    store_summary_enabled: bool = True
    summary_min_length: int = 50
    compress_on_store: bool = True
    
    # ä¸Šä¸‹æ–‡æ³¨å…¥è§„åˆ™
    inject_enabled: bool = True
    inject_threshold: float = 0.6
    inject_max_items: int = 3
    inject_debug: bool = False
    inject_debug_max_chars: int = 200
    inject_mode: str = "balanced"  # conservative | balanced | aggressive
    association_enabled: bool = True
    context_starved_min_chars: int = 16
    decision_block_enabled: bool = True
    decision_block_max: int = 3
    graph_inject_enabled: bool = True
    graph_max_items: int = 3
    graph_evidence_max_chars: int = 120
    adaptive_enabled: bool = True
    adaptive_min_threshold: float = 0.35
    adaptive_max_threshold: float = 0.75
    adaptive_step: float = 0.03
    adaptive_window: int = 40
    
    # æŠ¢æ•‘è§„åˆ™ (NOW.md)
    rescue_enabled: bool = True       # å¯ç”¨å‹ç¼©å‰æŠ¢æ•‘
    rescue_gold: bool = True        # æŠ¢æ•‘ #GOLD æ ‡è®°
    rescue_decisions: bool = True     # æŠ¢æ•‘å…³é”®å†³ç­–
    rescue_next_actions: bool = True # æŠ¢æ•‘ä¸‹ä¸€æ­¥è¡ŒåŠ¨


@dataclass
class ConversationContext:
    """
    å¯¹è¯ä¸Šä¸‹æ–‡
    
    è®°å½•æ¯è½®å¯¹è¯çš„ä¸Šä¸‹æ–‡çŠ¶æ€
    """
    round_num: int
    status: str  # "full", "summary", "compressed"
    content: str
    created_at: str
    summary: str = ""
    compressed: bool = False
    
    def to_dict(self) -> Dict:
        return asdict(self)


# ===================== Smart Context æ ¸å¿ƒ =====================

class SmartContextPlugin(NexusPlugin):
    """
    Smart Context æ’ä»¶
    
    ç¬¬äºŒå¤§è„‘æ ¸å¿ƒå­åŠŸèƒ½ï¼š
    1. å­˜å‚¨å¯¹è¯æ‘˜è¦ï¼ˆæ ¹æ®è§„åˆ™ï¼‰
    2. æ³¨å…¥è®°å¿†åº“ä¸Šä¸‹æ–‡
    3. æ ¹æ®å¯¹è¯è½®æ•°å‹ç¼©ä¸Šä¸‹æ–‡
    """
    
    def __init__(self):
        super().__init__()
        self.metadata = PluginMetadata(
            name="smart_context",
            version="3.1.0",
            description="Smart context - summary storage, memory injection, context compression",
            dependencies=["nexus_core", "session_manager"],
            hot_reloadable=True,
        )
        self.config = ContextCompressionConfig()
        self._nexus_core = None
        self._session_manager = None
        self._context_history: List[ConversationContext] = []
        self._current_round = 0
        self._graph_enabled = False
        self._inject_history: List[Dict[str, Any]] = []
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        """åˆå§‹åŒ–"""
        try:
            from ..core.plugin_system import get_plugin_registry
            registry = get_plugin_registry()
            self._nexus_core = registry.get("nexus_core")
            self._session_manager = registry.get("session_manager")
            
            if not self._nexus_core:
                print("âš ï¸ SmartContext: nexus_core æœªå°±ç»ª")
            
            # åŠ è½½é…ç½®
            if config.get("smart_context"):
                smart_cfg = config["smart_context"]
                self.config = ContextCompressionConfig(
                    full_rounds=smart_cfg.get("full_rounds", 8),
                    summary_rounds=smart_cfg.get("summary_rounds", 30),
                    compress_after_rounds=smart_cfg.get("compress_after_rounds", 50),
                    store_summary_enabled=smart_cfg.get("store_summary_enabled", True),
                    inject_enabled=smart_cfg.get("inject_enabled", True),
                    inject_threshold=smart_cfg.get("inject_threshold", 0.6),
                    inject_max_items=smart_cfg.get("inject_max_items", 3),
                    inject_debug=smart_cfg.get("inject_debug", False),
                    inject_debug_max_chars=smart_cfg.get("inject_debug_max_chars", 200),
                    inject_mode=smart_cfg.get("inject_mode", "balanced"),
                    association_enabled=smart_cfg.get("association_enabled", True),
                    context_starved_min_chars=smart_cfg.get("context_starved_min_chars", 16),
                    decision_block_enabled=smart_cfg.get("decision_block_enabled", True),
                    decision_block_max=smart_cfg.get("decision_block_max", 3),
                    graph_inject_enabled=smart_cfg.get("graph_inject_enabled", True),
                    graph_max_items=smart_cfg.get("graph_max_items", 3),
                    graph_evidence_max_chars=smart_cfg.get("graph_evidence_max_chars", 120),
                    adaptive_enabled=smart_cfg.get("adaptive_enabled", True),
                    adaptive_min_threshold=smart_cfg.get("adaptive_min_threshold", 0.35),
                    adaptive_max_threshold=smart_cfg.get("adaptive_max_threshold", 0.75),
                    adaptive_step=smart_cfg.get("adaptive_step", 0.03),
                    adaptive_window=smart_cfg.get("adaptive_window", 40),
                )
            graph_cfg = config.get("graph", {}) if isinstance(config.get("graph", {}), dict) else {}
            self._graph_enabled = bool(graph_cfg.get("enabled", False))
            if self._graph_enabled:
                configure_graph(
                    enabled=True,
                    base_path=config.get("paths", {}).get("base", "."),
                    db_path=graph_cfg.get("db_path"),
                )
            
            print(f"âœ… SmartContext åˆå§‹åŒ–å®Œæˆ (è§„åˆ™: {self.config.full_rounds}è½®å®Œæ•´/{self.config.summary_rounds}è½®æ‘˜è¦/{self.config.compress_after_rounds}è½®å‹ç¼©)")
            return True
            
        except Exception as e:
            print(f"âŒ SmartContext åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def start(self) -> bool:
        """å¯åŠ¨"""
        print("âœ… SmartContext å¯åŠ¨")
        return True
    
    async def stop(self) -> bool:
        """åœæ­¢"""
        print("âœ… SmartContext åœæ­¢")
        return True
    
    # ===================== å¯¹è¯è½®æ•°ç®¡ç† =====================
    
    def get_current_round(self, conversation_id: str) -> int:
        """
        è·å–å½“å‰å¯¹è¯è½®æ•°
        
        ä»ä¼šè¯ç®¡ç†å™¨è·å–å½“å‰è½®æ•°
        """
        if self._session_manager and conversation_id:
            try:
                session = self._session_manager.get_session(conversation_id)
                if session and getattr(session, "chunk_count", 0) > 0:
                    return int(session.chunk_count)
            except Exception:
                pass
        return self._current_round
    
    def should_compress(self, round_num: int) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å‹ç¼©
        
        Returns:
            (should_compress, reason)
        """
        if round_num <= self.config.full_rounds:
            return False, "full"  # æœ€è¿‘ N è½®å®Œæ•´ä¿ç•™
        
        if round_num <= self.config.summary_rounds:
            return True, "summary"  # ä¸­é—´çš„è½®æ•°åªä¿ç•™æ‘˜è¦
        
        return True, "compress"  # æ›´æ—©çš„è½®æ•°å‹ç¼©
    
    # ===================== ä¸Šä¸‹æ–‡å¤„ç† =====================
    
    def process_round(self, 
                     conversation_id: str,
                     round_num: int,
                     user_message: str,
                     ai_response: str) -> Dict[str, Any]:
        """
        å¤„ç†å•è½®å¯¹è¯
        
        æ ¹æ®è½®æ•°å†³å®šå¤„ç†æ–¹å¼ï¼š
        - 0-8 è½®ï¼šå®Œæ•´ä¿ç•™
        - 9-30 è½®ï¼šåªä¿ç•™æ‘˜è¦
        - 30+ è½®ï¼šå‹ç¼©/å½’æ¡£
        
        Args:
            conversation_id: å¯¹è¯ ID
            round_num: å½“å‰è½®æ•°
            user_message: ç”¨æˆ·æ¶ˆæ¯
            ai_response: AI å›å¤
            
        Returns:
            å¤„ç†ç»“æœ
        """
        result = {
            "conversation_id": conversation_id,
            "round_num": round_num,
            "status": "unknown",
            "stored": False,
        }
        
        should_compress, reason = self.should_compress(round_num)
        
        if reason == "full":
            # å®Œæ•´ä¿ç•™
            result["status"] = "full"
            result["content"] = ai_response
            result["compressed"] = False
            
        elif reason == "summary":
            # åªä¿ç•™æ‘˜è¦
            result["status"] = "summary"
            summary = self._extract_summary(ai_response)
            result["summary"] = summary
            result["compressed"] = False
            
        else:  # compress
            # å‹ç¼©
            result["status"] = "compressed"
            summary = self._extract_summary(ai_response)
            result["summary"] = summary
            result["compressed"] = True
        
        # å­˜å‚¨
        if self._nexus_core:
            self._store_context(conversation_id, round_num, result)
            if self.config.decision_block_enabled:
                blocks = self._extract_decision_blocks(f"{user_message}\n{ai_response}")
                self._store_decision_blocks(conversation_id, round_num, blocks)
            result["stored"] = True
        
        # æ›´æ–°å†å²
        self._current_round = round_num
        
        return result

    def _call_nexus(self, method_name: str, *args, **kwargs):
        if not self._nexus_core:
            return None
        method = getattr(self._nexus_core, method_name, None)
        if not callable(method):
            return None
        try:
            result = method(*args, **kwargs)
            if asyncio.iscoroutine(result):
                return run_coro_sync(result)
            return result
        except Exception as e:
            print(f"âš ï¸ SmartContext: è°ƒç”¨ nexus_core.{method_name} å¤±è´¥: {e}")
            return None
    
    def _extract_summary(self, response: str) -> str:
        """
        æå–æ‘˜è¦
        
        ä¼˜å…ˆçº§ï¼š
        1. JSON æ ¼å¼
        2. ## ğŸ“‹ æ€»ç»“ æ ¼å¼
        3. é»˜è®¤æ‘˜è¦
        """
        # JSON æ ¼å¼
        json_match = re.search(r'```json\s*\n([\s\S]*?)\n```', response)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                return data.get("æœ¬æ¬¡æ ¸å¿ƒäº§å‡º", data.get("æ ¸å¿ƒäº§å‡º", ""))
            except json.JSONDecodeError:
                pass
        
        # ## ğŸ“‹ æ€»ç»“ æ ¼å¼
        summary_match = re.search(r'## ğŸ“‹ æ€»ç»“[^\n]*\n([\s\S]*?)(?=\n\n|$)', response)
        if summary_match:
            return summary_match.group(1).strip()
        
        # é»˜è®¤æ‘˜è¦
        return response[:100].strip() + "..."
    
    def _store_context(self, conversation_id: str, round_num: int, context: Dict):
        """
        å­˜å‚¨ä¸Šä¸‹æ–‡åˆ°å‘é‡åº“
        """
        try:
            if context["status"] == "full":
                # å®Œæ•´å†…å®¹
                self._call_nexus(
                    "add_document",
                    content=context["content"],
                    title=f"å¯¹è¯ {conversation_id} - è½®{round_num} (å®Œæ•´)",
                    tags=f"type:full,round:{round_num},conversation:{conversation_id}"
                )
                
            elif context["status"] == "summary":
                # åªå­˜æ‘˜è¦
                self._call_nexus(
                    "add_document",
                    content=f"[æ‘˜è¦] {context['summary']}",
                    title=f"å¯¹è¯ {conversation_id} - è½®{round_num} (æ‘˜è¦)",
                    tags=f"type:summary,round:{round_num},conversation:{conversation_id}"
                )
                
            else:  # compressed
                # å‹ç¼©å­˜å‚¨
                self._call_nexus(
                    "add_document",
                    content=f"[å·²å‹ç¼©] {context['summary']}",
                    title=f"å¯¹è¯ {conversation_id} - è½®{round_num} (å·²å‹ç¼©)",
                    tags=f"type:compressed,round:{round_num},conversation:{conversation_id}"
                )
                
        except Exception as e:
            print(f"âš ï¸ å­˜å‚¨ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
    
    # ===================== åŠŸèƒ½ 1: æ‘˜è¦å­˜å‚¨ =====================
    
    def should_store_summary(self, response: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å­˜å‚¨æ‘˜è¦"""
        if not self.config.store_summary_enabled:
            return False
        
        if len(response) < self.config.summary_min_length:
            return False
        
        return True
    
    def extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        words = re.findall(r'\b\w+\b', text.lower())
        
        stop_words = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'è¿™', 'é‚£',
            'å’Œ', 'å°±', 'éƒ½', 'ä¹Ÿ', 'ä¼š', 'å¯ä»¥', 'ä»€ä¹ˆ', 'æ€ä¹ˆ',
            'å¦‚ä½•', 'æœ‰æ²¡æœ‰', 'æ˜¯ä¸æ˜¯', 'èƒ½ä¸èƒ½'
        }
        
        keywords = [w for w in words if w not in stop_words and len(w) > 2]
        return list(dict.fromkeys(keywords))[:5]

    def _is_context_starved(self, user_message: str) -> bool:
        msg = (user_message or "").strip()
        if len(msg) <= self.config.context_starved_min_chars:
            return True
        for kw in ("ç»§ç»­", "æ¥ç€", "åˆšæ‰", "ä¸Šæ¬¡", "ä¹‹å‰", "å»¶ç»­", "å¸®æˆ‘ç»§ç»­"):
            if kw in msg:
                return True
        return False

    def _extract_decision_blocks(self, text: str) -> List[str]:
        if not text:
            return []
        blocks: List[str] = []

        json_match = re.search(r'```json\s*\n([\s\S]*?)\n```', text)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                for key in ("æœ¬æ¬¡æ ¸å¿ƒäº§å‡º", "æ ¸å¿ƒäº§å‡º", "å†³ç­–ä¸Šä¸‹æ–‡"):
                    val = data.get(key)
                    if isinstance(val, str) and val.strip():
                        blocks.append(val.strip())
            except json.JSONDecodeError:
                pass

        decision_keywords = ("å†³å®š", "é€‰æ‹©", "é‡‡ç”¨", "ä½¿ç”¨", "ç»“è®º", "æ–¹æ¡ˆ", "ç­–ç•¥", "åˆ‡æ¢", "æ”¹ä¸º")
        for raw in text.splitlines():
            line = raw.strip(" \t-â€¢")
            if not line:
                continue
            if "#GOLD" in line:
                line = re.sub(r".*#GOLD[:\\s]*", "", line).strip()
            if any(k in line for k in decision_keywords) and len(line) >= 6:
                blocks.append(line)

        seen = set()
        uniq = []
        for b in blocks:
            if b in seen:
                continue
            seen.add(b)
            uniq.append(b)
        return uniq[: max(1, int(self.config.decision_block_max))]

    def _extract_graph_edges(self, block: str, conversation_id: str) -> List[Dict[str, Any]]:
        if not block:
            return []
        subj = f"conversation:{conversation_id}" if conversation_id else "workspace"
        edges: List[Dict[str, Any]] = []
        patterns = [
            (r"(ä½¿ç”¨|é‡‡ç”¨|é€‰æ‹©|æ”¹ä¸º|åˆ‡æ¢åˆ°)\s*([\\w\\-./]+)", "uses"),
            (r"(ä¾èµ–|åŸºäº)\s*([\\w\\-./]+)", "depends_on"),
            (r"(ç›®æ ‡|ç›®çš„)[:ï¼š]\\s*([^ï¼Œã€‚]+)", "goal"),
            (r"(å½±å“|å¯¼è‡´)\\s*([^ï¼Œã€‚]+)", "impacts"),
        ]
        for pattern, rel in patterns:
            match = re.search(pattern, block)
            if match:
                obj = match.group(2).strip()
                if 2 <= len(obj) <= 80:
                    edges.append(
                        {
                            "subj": subj,
                            "rel": rel,
                            "obj": obj,
                            "weight": 1.0,
                            "entity_types": {"subj": "conversation", "obj": "concept"},
                        }
                    )
        return edges[: self.config.decision_block_max]

    def _store_decision_blocks(self, conversation_id: str, round_num: int, blocks: List[str]) -> None:
        if not blocks:
            return
        for idx, block in enumerate(blocks, 1):
            self._call_nexus(
                "add_document",
                content=block,
                title=f"å†³ç­–å— {conversation_id} - è½®{round_num} ({idx})",
                tags=f"type:decision_block,round:{round_num},conversation:{conversation_id}"
            )
            if self._graph_enabled:
                for edge in self._extract_graph_edges(block, conversation_id):
                    graph_add_edge(
                        subj=edge["subj"],
                        rel=edge["rel"],
                        obj=edge["obj"],
                        weight=edge.get("weight", 1.0),
                        source=f"decision_block:{conversation_id}",
                        evidence_text=block,
                        conversation_id=conversation_id,
                        round_num=round_num,
                        entity_types=edge.get("entity_types"),
                    )
    
    def store_conversation(self, 
                          conversation_id: str,
                          user_message: str,
                          ai_response: str) -> Dict[str, Any]:
        """
        å­˜å‚¨å¯¹è¯æ‘˜è¦ï¼ˆå…¼å®¹æ—§ APIï¼‰
        """
        result = {
            "conversation_id": conversation_id,
            "stored": False,
        }
        
        if not self.should_store_summary(ai_response):
            return result
        
        if not self._nexus_core:
            return result
        
        try:
            # å­˜å‚¨åŸæ–‡
            self._call_nexus(
                "add_document",
                content=ai_response,
                title=f"å¯¹è¯ {conversation_id} - åŸæ–‡",
                tags=f"type:content,source:{conversation_id}"
            )
            result["stored"] = True
            
            # å­˜å‚¨æ‘˜è¦
            summary = self._extract_summary(ai_response)
            if summary:
                self._call_nexus(
                    "add_document",
                    content=f"[æ‘˜è¦] {summary}",
                    title=f"å¯¹è¯ {conversation_id} - æ‘˜è¦",
                    tags=f"type:summary,source:{conversation_id}"
                )
            
            # å­˜å‚¨å…³é”®è¯
            keywords = self.extract_keywords(user_message + " " + ai_response)
            if keywords:
                self._call_nexus(
                    "add_document",
                    content=" ".join(keywords),
                    title=f"å¯¹è¯ {conversation_id} - å…³é”®è¯",
                    tags=f"type:keywords,source:{conversation_id}"
                )

            if self.config.decision_block_enabled:
                blocks = self._extract_decision_blocks(f"{user_message}\n{ai_response}")
                self._store_decision_blocks(conversation_id, 0, blocks)
                
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    # ===================== åŠŸèƒ½ 2: ä¸Šä¸‹æ–‡æ³¨å…¥ =====================
    
    def should_inject(self, user_message: str) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ³¨å…¥ä¸Šä¸‹æ–‡
        """
        if not self.config.inject_enabled:
            return False, "disabled"

        if self.config.association_enabled and self._is_context_starved(user_message):
            return True, "context_starved"
        
        question_patterns = [
            r'æ€ä¹ˆ', r'å¦‚ä½•', r'æ˜¯ä»€ä¹ˆ', r'ä¸ºä»€ä¹ˆ', r'å“ªäº›',
            r'åŒºåˆ«', r'å®ç°', r'ä½¿ç”¨', r'è§£å†³'
        ]
        
        for pattern in question_patterns:
            if re.search(pattern, user_message):
                return True, "question"
        
        keywords = self.extract_keywords(user_message)
        mode = (self.config.inject_mode or "balanced").strip().lower()
        if mode == "aggressive":
            if any(k for k in keywords if len(k) > 3):
                return True, "keyword"
        elif mode == "conservative":
            if any(k for k in keywords if len(k) > 8):
                return True, "technical_term"
        else:  # balanced
            if any(k for k in keywords if len(k) > 6):
                return True, "technical_term"
        
        return False, "none"
    
    def inject_memory(self, user_message: str) -> List[Dict]:
        """
        æ³¨å…¥è®°å¿†åº“ä¸Šä¸‹æ–‡
        """
        should_inject, reason = self.should_inject(user_message)
        
        if not should_inject:
            if self.config.inject_debug:
                print(f"[SmartContext] INJECT skip reason={reason}")
            return []
        
        if not self._nexus_core:
            if self.config.inject_debug:
                print("[SmartContext] INJECT skip nexus_core=missing")
            return []
        
        try:
            max_items = self.config.inject_max_items
            threshold = self.config.inject_threshold
            if reason == "context_starved":
                max_items = max(1, min(2, max_items))
                threshold = max(0.0, min(1.0, threshold * 0.85))

            results = self._call_nexus("search_recall", user_message, max_items) or []
            
            filtered = [
                {
                    "content": r.content,
                    "source": r.source,
                    "relevance": r.relevance,
                }
                for r in results
                if r.relevance >= threshold
            ]
            if self.config.inject_debug:
                sources = [r.get("source", "unknown") for r in filtered]
                sample = (filtered[0]["content"][: self.config.inject_debug_max_chars] if filtered else "")
                print(
                    f"[SmartContext] INJECT ok reason={reason} topk={len(filtered)}/{len(results)} "
                    f"threshold={threshold} sources={sources} sample={sample!r}"
                )
            
            graph_items = self._inject_graph_associations(user_message, reason)
            final = filtered + graph_items
            self._record_inject_event(reason, len(final))
            return final
            
        except Exception as e:
            print(f"âš ï¸ è®°å¿†æ³¨å…¥å¤±è´¥: {e}")
            return []

    def _record_inject_event(self, reason: str, injected_count: int) -> None:
        if not self.config.adaptive_enabled:
            return
        self._inject_history.append(
            {
                "reason": reason,
                "count": int(injected_count),
            }
        )
        if len(self._inject_history) >= int(self.config.adaptive_window):
            self._tune_adaptive()

    def _tune_adaptive(self) -> None:
        if not self._inject_history:
            return
        window = int(self.config.adaptive_window)
        if window <= 0:
            return
        recent = self._inject_history[-window:]
        success = sum(1 for r in recent if r.get("count", 0) > 0)
        ratio = success / float(len(recent))

        step = float(self.config.adaptive_step)
        new_threshold = self.config.inject_threshold
        if ratio < 0.35:
            new_threshold = min(self.config.adaptive_max_threshold, self.config.inject_threshold + step)
        elif ratio > 0.7:
            new_threshold = max(self.config.adaptive_min_threshold, self.config.inject_threshold - step)

        if new_threshold != self.config.inject_threshold:
            if self.config.inject_debug:
                print(
                    f"[SmartContext] ADAPT threshold {self.config.inject_threshold:.2f} -> {new_threshold:.2f} "
                    f"(ratio={ratio:.2f}, window={len(recent)})"
                )
            self.config.inject_threshold = new_threshold

    def _inject_graph_associations(self, user_message: str, reason: str) -> List[Dict]:
        if not (self._graph_enabled and self.config.graph_inject_enabled):
            return []
        if reason not in {"context_starved", "question", "technical_term", "keyword"}:
            return []

        keywords = self.extract_keywords(user_message)
        if not keywords:
            return []

        max_items = max(1, int(self.config.graph_max_items))
        evidence_max = max(0, int(self.config.graph_evidence_max_chars))
        out: List[Dict] = []
        for kw in keywords[: max_items]:
            edges = graph_related_with_evidence(kw, limit=max_items, evidence_limit=1)
            for e in edges:
                ev = ""
                evidence = e.get("evidence") or []
                if evidence:
                    ev = (evidence[0].get("text") or "")[:evidence_max]
                content = f"{e.get('subj')} {e.get('rel')} {e.get('obj')}"
                if ev:
                    content = f"{content} | è¯æ®: {ev}"
                out.append(
                    {
                        "content": content,
                        "source": "graph",
                        "relevance": e.get("weight", 1.0),
                    }
                )
        if self.config.inject_debug and out:
            print(f"[SmartContext] GRAPH inject count={len(out)} keywords={keywords[:max_items]}")
        return out[: max_items]
    
    def generate_context_prompt(self, user_message: str) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡æç¤ºè¯
        """
        results = self.inject_memory(user_message)
        
        if not results:
            return ""
        
        parts = ["## ç›¸å…³è®°å¿†", ""]
        
        for i, r in enumerate(results, 1):
            parts.append(f"ã€{i}ã€‘({r.get('source', 'æœªçŸ¥')} - {r.get('relevance', 0):.2f})")
            parts.append(r.get('content', '')[:200])
            parts.append("")
        
        return "\n".join(parts)
    
    # ===================== åŠŸèƒ½ 3: å‹ç¼©å‰æŠ¢æ•‘ (NOW.md) =====================
    
    def rescue_before_compress(self, conversation: str) -> Dict[str, Any]:
        """
        å‹ç¼©å‰æŠ¢æ•‘
        
        ä»å¯¹è¯ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ä¿å­˜åˆ° NOW.md
        """
        if not self.config.rescue_enabled:
            return {"skipped": True, "reason": "rescue_disabled"}
        
        result = {"decisions_rescued": 0, "goals_rescued": 0, "questions_rescued": 0, "saved": False}
        
        try:
            from .now_manager import NOWManager
            now = NOWManager()
            
            # æå– #GOLD æ ‡è®°
            if self.config.rescue_gold:
                gold_matches = re.findall(r'#GOLD[:\s]*(.+?)(?:\n|$)', conversation)
                for match in gold_matches:
                    if match.strip() and match.strip() not in now.state.get("decisions", []):
                        now.state.setdefault("decisions", []).append(match.strip())
                        result["decisions_rescued"] += 1
            
            # æå–å…³é”®å†³ç­–
            if self.config.rescue_decisions:
                for keyword in ["å†³å®š", "é€‰æ‹©", "é‡‡ç”¨", "ä½¿ç”¨"]:
                    if keyword in conversation:
                        idx = conversation.find(keyword)
                        if idx != -1:
                            context = conversation[max(0, idx-30):idx+70].strip()
                            if context not in now.state.get("next_actions", []):
                                now.state.setdefault("next_actions", []).append(context)
                                result["goals_rescued"] += 1
            
            # æå–å¾…è§£å†³é—®é¢˜
            if self.config.rescue_next_actions:
                for match in re.findall(r'[?ï¼Ÿ](.+?)(?:\n|$)', conversation):
                    if match.strip() and len(match.strip()) > 5 and match.strip() not in now.state.get("open_questions", []):
                        now.state.setdefault("open_questions", []).append(match.strip())
                        result["questions_rescued"] += 1
            
            total = result["decisions_rescued"] + result["goals_rescued"] + result["questions_rescued"]
            if total > 0:
                now.save()
                result["saved"] = True
                
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def get_rescue_context(self) -> str:
        """è·å–æŠ¢æ•‘ä¸Šä¸‹æ–‡"""
        try:
            from .now_manager import NOWManager
            return NOWManager().format_context()
        except:
            return ""
    
    def clear_rescue(self):
        """æ¸…ç©ºæŠ¢æ•‘çŠ¶æ€"""
        try:
            from .now_manager import NOWManager
            NOWManager().clear()
        except:
            pass
    
    # ===================== ä¾¿æ·å‡½æ•° =====================

def store_conversation(conversation_id: str, user_message: str, ai_response: str) -> Dict:
    """å­˜å‚¨å¯¹è¯æ‘˜è¦ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    from ..compat import nexus_init, nexus_add

    if not nexus_init():
        return {"error": "nexus init failed", "stored": False}

    def _extract_summary(text: str) -> str:
        json_match = re.search(r'```json\\s*\\n([\\s\\S]*?)\\n```', text)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                return data.get("æœ¬æ¬¡æ ¸å¿ƒäº§å‡º", data.get("æ ¸å¿ƒäº§å‡º", ""))
            except json.JSONDecodeError:
                pass
        summary_match = re.search(r'## ğŸ“‹ æ€»ç»“[^\\n]*\\n([\\s\\S]*?)(?=\\n\\n|$)', text)
        if summary_match:
            return summary_match.group(1).strip()
        return (text or "")[:100].strip()

    def _extract_keywords(text: str) -> List[str]:
        words = re.findall(r'\\b\\w+\\b', text.lower())
        stop_words = {
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'è¿™', 'é‚£',
            'å’Œ', 'å°±', 'éƒ½', 'ä¹Ÿ', 'ä¼š', 'å¯ä»¥', 'ä»€ä¹ˆ', 'æ€ä¹ˆ',
            'å¦‚ä½•', 'æœ‰æ²¡æœ‰', 'æ˜¯ä¸æ˜¯', 'èƒ½ä¸èƒ½'
        }
        keywords = [w for w in words if w not in stop_words and len(w) > 2]
        return list(dict.fromkeys(keywords))[:5]

    def _extract_decisions(text: str) -> List[str]:
        if not text:
            return []
        blocks: List[str] = []
        json_match = re.search(r'```json\\s*\\n([\\s\\S]*?)\\n```', text)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                for key in ("æœ¬æ¬¡æ ¸å¿ƒäº§å‡º", "æ ¸å¿ƒäº§å‡º", "å†³ç­–ä¸Šä¸‹æ–‡"):
                    val = data.get(key)
                    if isinstance(val, str) and val.strip():
                        blocks.append(val.strip())
            except json.JSONDecodeError:
                pass
        decision_keywords = ("å†³å®š", "é€‰æ‹©", "é‡‡ç”¨", "ä½¿ç”¨", "ç»“è®º", "æ–¹æ¡ˆ", "ç­–ç•¥", "åˆ‡æ¢", "æ”¹ä¸º")
        for raw in text.splitlines():
            line = raw.strip(" \\t-â€¢")
            if not line:
                continue
            if "#GOLD" in line:
                line = re.sub(r".*#GOLD[:\\s]*", "", line).strip()
            if any(k in line for k in decision_keywords) and len(line) >= 6:
                blocks.append(line)
        seen = set()
        uniq = []
        for b in blocks:
            if b in seen:
                continue
            seen.add(b)
            uniq.append(b)
        return uniq[:3]

    summary = _extract_summary(ai_response)
    nexus_add(ai_response, f"å¯¹è¯ {conversation_id} - åŸæ–‡", f"type:content,source:{conversation_id}")
    if summary:
        nexus_add(f"[æ‘˜è¦] {summary}", f"å¯¹è¯ {conversation_id} - æ‘˜è¦", f"type:summary,source:{conversation_id}")

    keywords = _extract_keywords(user_message + " " + ai_response)
    if keywords:
        nexus_add(" ".join(keywords), f"å¯¹è¯ {conversation_id} - å…³é”®è¯", f"type:keywords,source:{conversation_id}")

    decisions = _extract_decisions(user_message + "\\n" + ai_response)
    for idx, block in enumerate(decisions, 1):
        nexus_add(block, f"å†³ç­–å— {conversation_id} - ({idx})", f"type:decision_block,source:{conversation_id}")

    return {"stored": True, "conversation_id": conversation_id}


def inject_memory_context(user_message: str) -> str:
    """æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    from ..compat import nexus_init, nexus_recall

    if not nexus_init():
        return ""

    results = nexus_recall(user_message, n=3)
    if not results:
        return ""

    parts = ["## ç›¸å…³è®°å¿†", ""]
    for i, r in enumerate(results, 1):
        parts.append(f"ã€{i}ã€‘({r.source} - {getattr(r, 'relevance', 0):.2f})")
        parts.append((r.content or "")[:200])
        parts.append("")
    return "\n".join(parts)


# ===================== å‘åå…¼å®¹ =====================

__all__ = [
    "SmartContextPlugin",
    "ContextCompressionConfig",
    "ConversationContext",
    "store_conversation",
    "inject_memory_context",
]
