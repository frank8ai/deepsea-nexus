"""
è‡ªåŠ¨ Flush æ¨¡å—

åŠŸèƒ½ï¼š
- å®šæ—¶å½’æ¡£æ—§ä¼šè¯
- æ¸…ç†ä½æ´»è·ƒ chunks
- æŒ‰æ—¶é—´ç­–ç•¥ç®¡ç†å­˜å‚¨
- å‹ç¼©å½’æ¡£åŠŸèƒ½

F5. è‡ªåŠ¨ Flush
"""

import os
import shutil
import json
import gzip
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import yaml


class FlushManager:
    """Flush ç®¡ç†å™¨"""
    
    def __init__(self, base_path: str = None, config: Dict = None):
        """
        åˆå§‹åŒ– Flush ç®¡ç†å™¨
        
        Args:
            base_path: è®°å¿†åº“æ ¹è·¯å¾„
            config: é…ç½®é¡¹
        """
        if base_path is None:
            self.base_path = os.path.expanduser("~/.openclaw/workspace/memory")
        else:
            self.base_path = base_path
        
        # é»˜è®¤é…ç½®
        self.config = {
            "enabled": True,
            "archive_time": "03:00",  # æ¯æ—¥å‡Œæ™¨ 3 ç‚¹
            "archive_monthly": True,
            "archive_dir": "archive",
            "keep_active_days": 30,   # æ´»è·ƒä¼šè¯ä¿ç•™ 30 å¤©
            "keep_archived_days": 90, # å½’æ¡£ä¼šè¯ä¿ç•™ 90 å¤©
            "min_chunks_to_archive": 5,  # è‡³å°‘ 5 ä¸ª chunks æ‰å½’æ¡£
            "compress_enabled": True,    # å¯ç”¨å‹ç¼©
        }
        
        # åˆå¹¶é…ç½®
        if config:
            self.config.update(config)
        
        # ç¡®ä¿å½’æ¡£ç›®å½•å­˜åœ¨
        self.archive_path = os.path.join(self.base_path, self.config["archive_dir"])
        os.makedirs(self.archive_path, exist_ok=True)
    
    def should_archive(self, session_info: Dict) -> bool:
        """
        åˆ¤æ–­ä¼šè¯æ˜¯å¦åº”è¯¥å½’æ¡£
        
        Args:
            session_info: ä¼šè¯ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥å½’æ¡£
        """
        # æ£€æŸ¥ chunks æ•°é‡
        if session_info.get("chunk_count", 0) < self.config["min_chunks_to_archive"]:
            return False
        
        # æ£€æŸ¥æœ€åæ´»è·ƒæ—¶é—´
        last_active = session_info.get("last_active", "")
        if last_active:
            try:
                last_date = datetime.fromisoformat(last_active)
                days_ago = (datetime.now() - last_date).days
                
                # å¦‚æœ 7 å¤©å†…æœ‰è¿‡æ´»è·ƒï¼Œä¸å½’æ¡£
                if days_ago < 7:
                    return False
                
                # 30 å¤©å‰æ´»è·ƒçš„ï¼Œå½’æ¡£
                if days_ago > self.config["keep_active_days"]:
                    return True
            except Exception:
                pass
        
        # é»˜è®¤ä¸å½’æ¡£
        return False
    
    def archive_session(self, session_id: str, session_info: Dict) -> bool:
        """
        å½’æ¡£å•ä¸ªä¼šè¯
        
        Args:
            session_id: ä¼šè¯ ID
            session_info: ä¼šè¯ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»ºå½’æ¡£ç›®å½• (æŒ‰å¹´æœˆ)
            month_dir = datetime.now().strftime("%Y-%m")
            target_dir = os.path.join(self.archive_path, month_dir)
            os.makedirs(target_dir, exist_ok=True)
            
            # ç§»åŠ¨ä¼šè¯æ–‡ä»¶
            # å‡è®¾ä¼šè¯å­˜å‚¨åœ¨ sessions/{session_id}.json
            source_file = os.path.join(self.base_path, "sessions", f"{session_id}.json")
            target_file = os.path.join(target_dir, f"{session_id}.json")
            
            if os.path.exists(source_file):
                shutil.move(source_file, target_file)
                
                # å‹ç¼©å½’æ¡£æ–‡ä»¶
                if self.config.get("compress_enabled", True):
                    compressed_file = self.compress_file(target_file)
                    if compressed_file:
                        os.remove(target_file)  # åˆ é™¤åŸå§‹æ–‡ä»¶
                        print(f"âœ“ å·²å½’æ¡£å¹¶å‹ç¼©: {session_id} -> {month_dir}/")
                    else:
                        print(f"âœ“ å·²å½’æ¡£: {session_id} -> {month_dir}/")
                else:
                    print(f"âœ“ å·²å½’æ¡£: {session_id} -> {month_dir}/")
                return True
            else:
                # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿè®°å½•å½’æ¡£ä¿¡æ¯
                info_file = os.path.join(target_dir, f"{session_id}_info.json")
                with open(info_file, 'w', encoding='utf-8') as f:
                    json.dump(session_info, f, ensure_ascii=False, indent=2)
                print(f"âœ“ å·²å½’æ¡£(ä¿¡æ¯): {session_id} -> {month_dir}/")
                return True
                
        except Exception as e:
            print(f"âœ— å½’æ¡£å¤±è´¥ {session_id}: {e}")
            return False
    
    def compress_file(self, file_path: str) -> str:
        """
        å‹ç¼©å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        compressed_path = file_path + ".gz"
        try:
            with open(file_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    f_out.write(f_in.read())
            return compressed_path
        except Exception as e:
            print(f"å‹ç¼©å¤±è´¥ {file_path}: {e}")
            return ""
    
    def decompress_file(self, compressed_path: str, output_path: str = None) -> str:
        """
        è§£å‹æ–‡ä»¶
        
        Args:
            compressed_path: å‹ç¼©æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: è§£å‹åçš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = compressed_path.replace('.gz', '')
        
        try:
            with gzip.open(compressed_path, 'rb') as f_in:
                with open(output_path, 'wb') as f_out:
                    f_out.write(f_in.read())
            return output_path
        except Exception as e:
            print(f"è§£å‹å¤±è´¥ {compressed_path}: {e}")
            return ""
    
    def read_compressed_session(self, session_id: str) -> Optional[Dict]:
        """
        è¯»å–å‹ç¼©çš„ä¼šè¯æ–‡ä»¶
        
        Args:
            session_id: ä¼šè¯ ID
            
        Returns:
            Dict: ä¼šè¯ä¿¡æ¯ æˆ– None
        """
        # æŸ¥æ‰¾å‹ç¼©æ–‡ä»¶
        for root, dirs, files in os.walk(self.archive_path):
            for file in files:
                if file == f"{session_id}.json.gz":
                    compressed_path = os.path.join(root, file)
                    decompressed_path = self.decompress_file(compressed_path)
                    if decompressed_path:
                        try:
                            with open(decompressed_path, 'r', encoding='utf-8') as f:
                                return json.load(f)
                        except Exception:
                            pass
                    return None
                elif file == f"{session_id}.json":
                    # æœªå‹ç¼©çš„ç‰ˆæœ¬
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            return json.load(f)
                    except Exception:
                        pass
        return None
    
    def daily_flush(self, session_manager) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¯æ—¥ Flush
        
        Args:
            session_manager: SessionManager å®ä¾‹
            
        Returns:
            Dict: æ‰§è¡Œç»Ÿè®¡
        """
        stats = {
            "total_sessions": 0,
            "archived": 0,
            "compressed": 0,
            "skipped": 0,
            "errors": 0,
            "timestamp": datetime.now().isoformat()
        }
        
        if not self.config["enabled"]:
            print("Flush å·²ç¦ç”¨")
            return stats
        
        print(f"ğŸ”„ å¼€å§‹æ¯æ—¥ Flush ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
        
        # è·å–æ‰€æœ‰ä¼šè¯
        sessions = session_manager.sessions
        stats["total_sessions"] = len(sessions)
        
        for session_id, info in sessions.items():
            try:
                info_dict = info.to_dict() if hasattr(info, 'to_dict') else info
                
                if self.should_archive(info_dict):
                    if self.archive_session(session_id, info_dict):
                        session_manager.archive_session(session_id)
                        stats["archived"] += 1
                        stats["compressed"] += 1  # å‹ç¼©è®¡æ•°
                    else:
                        stats["errors"] += 1
                else:
                    stats["skipped"] += 1
                    
            except Exception as e:
                print(f"âœ— å¤„ç†ä¼šè¯å¤±è´¥ {session_id}: {e}")
                stats["errors"] += 1
        
        # æ¸…ç†æ—§å½’æ¡£
        self.clean_old_archives()
        
        print(f"âœ“ Flush å®Œæˆ: å½’æ¡£ {stats['archived']}, å‹ç¼© {stats['compressed']}, è·³è¿‡ {stats['skipped']}")
        
        return stats
    
    def clean_old_archives(self):
        """æ¸…ç†æ—§å½’æ¡£æ–‡ä»¶"""
        if not self.config.get("keep_archived_days"):
            return
        
        cutoff_date = datetime.now() - timedelta(days=self.config["keep_archived_days"])
        
        for root, dirs, files in os.walk(self.archive_path):
            for file in files:
                if file.endswith("_info.json"):
                    try:
                        file_path = os.path.join(root, file)
                        with open(file_path, 'r', encoding='utf-8') as f:
                            info = json.load(f)
                        
                        last_active = info.get("last_active", "")
                        if last_active:
                            last_date = datetime.fromisoformat(last_active)
                            if last_date < cutoff_date:
                                os.remove(file_path)
                                print(f"ğŸ—‘ï¸ å·²æ¸…ç†æ—§å½’æ¡£: {file}")
                    except Exception:
                        pass
    
    def get_archive_stats(self) -> Dict[str, Any]:
        """è·å–å½’æ¡£ç»Ÿè®¡"""
        stats = {
            "total_archives": 0,
            "compressed_count": 0,
            "by_month": {}
        }
        
        if not os.path.exists(self.archive_path):
            return stats
        
        for item in os.listdir(self.archive_path):
            item_path = os.path.join(self.archive_path, item)
            if os.path.isdir(item_path):
                files = os.listdir(item_path)
                json_count = len([f for f in files if f.endswith(".json")])
                gz_count = len([f for f in files if f.endswith(".json.gz")])
                stats["by_month"][item] = {
                    "total": json_count + gz_count,
                    "compressed": gz_count
                }
                stats["total_archives"] += json_count + gz_count
                stats["compressed_count"] += gz_count
        
        return stats
    
    def manual_flush(self, session_manager, dry_run: bool = True) -> Dict[str, Any]:
        """
        æ‰‹åŠ¨è§¦å‘ Flushï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        Args:
            session_manager: SessionManager å®ä¾‹
            dry_run: True åˆ™åªé¢„è§ˆï¼Œä¸å®é™…æ‰§è¡Œ
            
        Returns:
            Dict: é¢„è§ˆ/æ‰§è¡Œç»Ÿè®¡
        """
        stats = {
            "dry_run": dry_run,
            "sessions_to_archive": [],
            "total_sessions": len(session_manager.sessions)
        }
        
        for session_id, info in session_manager.sessions.items():
            info_dict = info.to_dict() if hasattr(info, 'to_dict') else info
            
            if self.should_archive(info_dict):
                stats["sessions_to_archive"].append({
                    "session_id": session_id,
                    "topic": info.topic,
                    "last_active": info.last_active,
                    "chunks": info.chunk_count
                })
        
        if dry_run:
            print(f"ğŸ” Dry Run - å°†å½’æ¡£ {len(stats['sessions_to_archive'])} ä¸ªä¼šè¯:")
            for s in stats["sessions_to_archive"]:
                print(f"  - {s['session_id']}: {s['topic']} ({s['chunks']} chunks)")
        else:
            return self.daily_flush(session_manager)
        
        return stats


# æµ‹è¯•
if __name__ == "__main__":
    from session_manager import SessionManager
    
    # åˆ›å»ºæµ‹è¯•ä¼šè¯
    manager = SessionManager()
    sid = manager.start_session("æµ‹è¯•ä¼šè¯")
    manager.add_chunk(sid)
    
    # Flush æµ‹è¯•
    flush_mgr = FlushManager()
    
    # é¢„è§ˆ
    result = flush_mgr.manual_flush(manager, dry_run=True)
    print(f"\né¢„è§ˆ: {len(result['sessions_to_archive'])} ä¸ªä¼šè¯å¾…å½’æ¡£")
